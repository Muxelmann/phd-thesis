\section{Distributed Systems}
\label{ch3:sec:distributed-systems}

As discussed in the literature review in Chapter \ref{ch-literature}, several mechanisms exist to decentralise control of DERs.
For their reactivity, pro-activeness, social ability and flexibility however, the Multi Agent System (MAS) distinguished itself from traditional software and hardware systems, which is why it was also chosen for the coordination of smart EV charging.
Several agent package implementations exist, each following different interaction paradigms.
Some of these paradigms include ``Belief, Desire and Intention'' (BDI), neutral behaviour or other specialised functionality \cite{Luck2004}.
From the catalogue of MAS paradigms, the Java Agent Development Framework (JADE) was chosen, since it natively implements the Foundation for Intelligent Physical Agent (FIPA) specification \cite{JADE-website, FIPA-agent-specs}.
Furthermore, JADE is an application independent package that has become quite popular, as seen by the increasing number of publications \cite{Karfopoulos2013, Eddy2011, Kuo2013, Mocci2014, Li2017}.

In this work, multiple virtual trading agents are used to negotiate their corresponding EV charging profile with other trading agents.
Tying virtual agents to a physical entity is not new \cite{Dimeas2005, Nguyen2011, Nagata2011, Nagata2012}, and allows a clear decoupling of the data storing and interacting entities.
In previous work however, physical agents directly controlled the virtual entities whilst the agents in the presented work negotiate schedules that will be applied after schedule ratification.
Therefore, the physical agent is never notified of any intermediate charging profile and only receives the final schedule.
Scheduling and inter-agent communication is achieved by so called ``broker'' agents that follow the Brokering Interaction Protocol (BIP) to serve the final charging profile when requested.
It is those broker agents that communicate and negotiate with each other by following the Contact-Net Protocol (CNP).
All these FIPA protocols are based on the FIPA Agent Communication Language (ACL) that is required to communicate over a shared telecommunications infrastructure since it standardises the communication ontology and schemas.
Following this standard also opens the possibility of including different agent packages into the scheduling mechanism, but this lies outside the work's scope.
Explanations of all protocols that were used in this implementation of FIPA agents are included in Appendix \ref{appx-b:multi-agent-systems}.
In this work, each broker is linked to a single EV and negotiates its charging profile over the aforementioned scheduling horizon, $T_\text{sch}$.
This link is shown in Figure \ref{ch3:fig:agent-network}.

\input{_chapter3/fig/agent-network}

The example in Figure \ref{ch3:fig:agent-network} shows the structure of a MAS with three physical agents and six virtual agents.
A supplier and two loads are the physical agents and two charging EVS, respectively, which dispatch two brokers each.
One of the brokers is for buying energy, i.e. ``allocating'' energy, and the other one for selling energy, i.e. ``undoing'' energy.
With this kind of system architecture, the scheduling algorithm can be executed to mitigate potential charging spikes.

How this MAS is implemented, synchronised and desynchronised is explained in the following sections, Section \ref{ch3:subsec:implementation} and Section \ref{ch3:subsec:desynchronisation}, respectively.
Subsequently, in Section \ref{ch3:subsec:cases-and-metrics}, all case studies and performance metrics that are used to assess the MAS performance are outlined.

\subsection{MAS Implementation}
\label{ch3:subsec:implementation}

The MAS is implemented in Java and runs on a parallel compute cluster (i.e. the \textit{HTCondor} cluster at the former \textit{School of Systems Engineering} at the \textit{University of Reading}).
How the compute cluster was used to realise multiple agents is shown in Figure \ref{ch3:fig:agent-implementation}.

\input{_chapter1/fig/agent-implementation}

In this figure, Figure \ref{ch3:fig:agent-implementation}, at the laboratory workstation, a collection of MAS simulations is compiled in order to extensively cover the algorithm's operating spectrum.
More specifically, 10000 repetitions of the scheduling algorithm are queued for a single base load, but with different $\alpha$ and $\beta$ parameters.
Therefore, the algorithm's parameter sensitivity is probed at a resolution of 0.01 for both $\alpha$ and $\beta$, i.e. $\alpha \in \{0.01, 0.02, \dots, 1.00\}$ and $\beta \in \{0.01, 0.02, \dots, 1.00\}$.
This queue of 10000 simulations is then submitted to the \textit{HTCondor} master node, which schedules the execution of each simulation to its pool of workers.
Each worker internally simulates an instance of the MAS and stores its outputs to a fast networked storage, which also serves as the worker's data source
Given the 1540 load profiles from the Irish dataset and assuming a typical distribution network of 55 customers, a theoretical limit of $6.11\times10^{101}$ simulations would exist.
Due to the limited time and size of the available worker pool (ca. 200 workers), a total number of $1.5\times10^{7}$ MAS simulations is chosen to yield a sufficiently accurate estimate of the algorithm's performance.
For all submitted simulations a relatively high EV uptake of 20\% was chosen in order to maximise the effect of badly scheduled EV charging, and in order to give the algorithm a larger energy volume when adjusting the EV charging schedules.
Also, in the diagram in Figure \ref{ch3:fig:agent-implementation}, all bold arrows indicate fast data transmissions (used to acquire and store the datasets that are used for each MAS simulation), solid arrow indicates the loading of simulation data, and the dotted arrows indicate the software messages to submit and launch the MAS simulations.

\subsection{MAS Desynchronisation}
\label{ch3:subsec:desynchronisation}

Originally, the smart-charging algorithm was intended to run in a synchronised MAS environment, as shown in Figure \ref{ch3:fig:agent-synchronisation}.
However, when aiming to desynchronise this operation, two distinct ways exist:
Either, any idle state that is interrupted by the synchronising signal (which is shown in Figure \ref{ch3:fig:agent-synchronisation}) is removed and agent execution continues immediately, or agents are launched with a random jitter and operate in an execution loop with a fixed time delay.
Although the first approach would result in the quickest simulation execution, it still would require a synchronised start since one agent would already finish all algorithm iterations by the time a second agent joins the MAS.
Therefore, only the second way yields a truly desynchronised agent execution that still guarantees that all agents partake in the scheduling process.
Furthermore, using this jitter and therefore extending the execution time of each simulation makes the algorithm compliant with the compute cluster's terms of usage, since it would otherwise threaten to overload \textit{HTCondor} at managing the submission and data transfer between all workers.

In order to implement the second way of desynchronising agents, each agent is equipped with its individual loop timer that regulates its execution behaviour.
All agents are launched in quick succession and immediately begin their enumeration and scheduling tasks.
Desynchronisation amongst all agents is then achieved by introducing a jitter to both the agents' loop timers and the period between successive agent launches.
The resulting MAS then consisted of a completely desynchronised collection of agents, i.e. none of the agent's loop execution is aligned or dependent on any other agent's loop execution.
An example of this desynchronisation mechanism is presented in Figure \ref{ch3:fig:agent-desynchronisation}.

\input{_chapter3/fig/agent-desynchronisation}

From Figure \ref{ch3:fig:agent-desynchronisation}, the successful desynchronisation can be observed since the supplier never receives more than one message at a time.
Whilst the synchronised and desynchronised algorithm implementation do not differ in the scheduling method, their updating procedure does distinguish them.
More specifically, for the synchronised implementation, the algorithm obtains the complete demand (i.e. Equ. \ref{ch3:equ:updated-demand-profile}) after all EVs have sent their updated charging profiles.
The desynchronised implementation on the other hand receives intermittent updates of the network demand.
To investigate the difference in performance a set of cases and performance metrics are defined in the following section, Section~\ref{ch3:subsec:cases-and-metrics}.

\subsection{Cases and Performance Metrics}
\label{ch3:subsec:cases-and-metrics}

A set of load profiles is assessed with three different configurations:

\begin{enumerate}
	\item Synchronised algorithm execution
	\item Desynchronised algorithm execution with regular loop delays
	\item Desynchronised algorithm execution with irregular loop delays
\end{enumerate}

For each load profile, 10000 MASs are simulated to cover a high range of $\alpha$ and $\beta$ parameter pairs.
In this context each simulation is seen as an individual case study.
Therefore each case study executes up to 100 iterations after which the smart-charging algorithm terminates.
Throughout the progress of executing the algorithm, every EV's charging profile is recorded for each iteration.
Also, when the simulation terminates, the final aggregated charging profile is also recorded.
Therefore, an information on the development of the total demand profile can be obtained for every singe algorithm iteration.
The performance of the algorithm is then determined by quantifying the shape of the underlying demand profile.

Similar to the previous chapters, Chapter \ref{ch1} and Chapter \ref{ch2}, the Peak-to-Average Ratio (PAR) and Transient powers (TRA) are used as performance metrics for the demand profile.
The two metrics, respectively $\zeta_\text{PAR}(\textbf{p}_n)$ and $\zeta_\text{TRA}(\textbf{p}_n)$, where $\textbf{p}_n$ is the total demand profile, i.e. $\textbf{p}_n = \textbf{p}_\text{base} + \sum_{u=1}^U \textbf{p}_{\text{EV},u,n}$, for algorithm iteration $n$, and they are defined as follows:

\input{_chapter3/equ/performance-metrics}

As the total demand $\textbf{p}_n$ becomes flatter, i.e. by filling valleys instead of adding peaks, the gap between mean and maximum demand reduces, decreasing the output of $\zeta_\text{PAR}$.
However, if the total charging power of all EVs constructively superimposes at the same time, and if this additional power does not increase the daily demand peak, then $\zeta_\text{PAR}$ would still decrease despite the unwanted demand shape.
Therefore, the change in power, i.e. the mean transient, is also taken into assessed by $\zeta_\text{TRA}$, which is lowered when the change in power is reduced and thus the profile becomes smooth.

When the scheduling algorithm was detailed in Section \ref{ch3:subsec:scheduling-algorithm}, convergence for the synchronised case was guaranteed since the algorithm follows the D'Alembert Criterion.
This criterion holds if, for every iteration of the algorithm, the ratio between the current and previous algorithm outputs is less than one, i.e. the value is decreasing.
More specifically, this criterion is satisfied when

\input{_chapter3/equ/convergence-criterion}

These two convergence criteria in Equation \ref{ch3:equ:convergence-criterion-par} and Equation \ref{ch3:equ:convergence-criterion-tra} are limited to values of $\zeta_\text{PAR}$ and $\zeta_\text{PAR}$ greater than zero.
Whilst the ratio between maximum and mean can only reduce to a value of one, $\zeta_\text{PAR}$ satisfies this criterium.
$\zeta_\text{PAR}$ on the other hand may reduce to a value of zero.
To prevent this from happening, the number of EVs and their total demand are limited to a certain value that could not fully ``fill'' the network demand's valleys and lead to a perfectly flat demand profile.

Although the D'Alembert Criterion can be used to check whether the smart-charging algorithm converges, it cannot produce the rate of convergence.
Similar to Laplace, the rate of convergence is determined by an exponential decay function.
Since the underlying mathematical function is unknown, an estimated exponential is used instead.
The estimate is obtained by fitting an exponential function to the series of $\zeta_\text{PAR}$ and $\zeta_\text{PAR}$ values over all iterations, and by using the following definition of a simple exponential function:

\input{_chapter3/equ/exponential-function}

In Equation \ref{ch3:equ:performance-metrics-par}, $a$ is the zero-crossing point of this function and $b$ the rate of convergence.
For the scope of this chapter, $n$ is limited to $n \geq 0$.
The size of $b$ indicates how fast the values converged, which is why $b$ is used as a convergence indicator.
Values for $a$ and $b$ are found by reducing the error between the exponential function and the series of $\zeta_\text{PAR}$ or $\zeta_\text{TRA}$ values, i.e.:

\input{_chapter3/equ/find-exponential}

Results are therefore split into three parts.
In the first part, results are presented for the time-series evolution when using the algorithm in a synchronised MAS.
Different $\alpha$ and $\beta$ values are used to explore and show the sensitivity of the algorithm.
With this in mind the corresponding $\zeta_\text{PAR}$ and $\zeta_\text{TRA}$ values are presented to show their link to the underlying load profile's shape, and their convergence values, i.e. $b$ is also presented.
Finally, a complete set of final $\zeta_\text{PAR}$ and $\zeta_\text{TRA}$ values, as well as their convergence values, $b$, are plotted for the entire spectrum of $\alpha$ and $\beta$ pairs.
This is to show the sensitivity of the algorithm for the complete range of $\alpha$ and $\beta$.
The second step is then to introduce algorithm desynchronisation, but with regular loop delays, and repeat the complete analysis to compare it with the results in the first part.
In the third and last part, the algorithm desynchronisation is changed so that the algorithm's loop delays are irregular.
All results are once again compared to the preceding two parts of the results by following the same analysis.



