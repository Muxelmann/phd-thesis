\section{Control of ESMU}
\label{ch2:sec:control-of-esmu}

\input{_chapter2/fig/system-controller}

This section explains the dynamic control (i.e. the controller block as shown in Figure~\ref{ch2:subfig:proposed-dynamic-control-system}) which contains the two PID compensators to adjust operation around the predetermined ESMU schedule.
The first PID compensator is fed by the ESMU schedule and the other is fed by the MPC load estimations.
After the control system is detailed in this section the auto-regressive models which were used during the course of this research are also explained.

\subsection{Dynamic control}

The content of the dynamic control procedure is shown in Figure~\ref{ch2:fig:system-controller}.
Here two reference signals are used as inputs to the dynamic control.
The first reference signal is the SOC profile derived from the ESMU scheduled, $SOC(t)$, and the second is an estimated future network power, $\hat{p}_\text{net}(t+\Delta t)$.
These two inputs are fed into compensator PID$_1$ and compensator PID$_2$, respectively.
The output of each compensator is a corrective battery power component that, when summed, yields the next ESMU power (i.e. $p_1(t+\Delta t)$ and $p_2(t+\Delta t)$) which is applied to the ESMU model.
Each PID compensator also receives a feedback signal to compute the internal error states.
More specifically, PID$_1$ receives the most recent SOC value that is obtained from the ESMU model, $SOC^*(t)$, and PID$_2$ receives the network's most recent power demand, $p_\text{net}(t)$ (\hlrem{e.g.}\hladd{for example} through measurements by substation monitoring).

\nomenclature[J]{$p_\text{net}(t)$}{Most recent network demand at sample $t$, where $\textbf{p}_{net} = (p_\text{net}(t))$ and $p_\text{net}(t) \in \mathbb{R}$}
\nomenclature[J]{$SOC^*(t)$}{Battery's state of charge at sample $t$, where $SOC^*(t) \in [0, 1]$}
\nomenclature[J]{$E_\text{SOC}(t)$}{Error in state of charge at sample $t$, where $E_\text{SOC}(t) \in \mathbb{R}$}
\nomenclature[J]{$E_{p}(t)$}{Difference between current and predicting network power at sample $t$, where $E_{p}(t) \in \mathbb{R}$}
\nomenclature[J]{$\hat{p}_\text{net}(t+\Delta t)$}{Predicted next network power at sample $t$}
\nomenclature[J]{$\boldsymbol{\alpha}$}{PID weight vector for SOC compensator PID$_1$, where $\boldsymbol{\alpha} = \{\alpha_P, \alpha_I, \alpha_D\}$ and $\boldsymbol{\alpha} \in \mathbb{R}^3$}
\nomenclature[J]{$\boldsymbol{\beta}$}{PID weight vector for MPC compensator PID$_2$, where $\boldsymbol{\beta} = \{\beta_P, \beta_I, \beta_D\}$ and $\boldsymbol{\beta} \in \mathbb{R}^3$}
\nomenclature[J]{$\textbf{a}$}{Weight vector for compensator input regression of the AR model, where $\textbf{a} = \mathbb{R}^{N}$}
\nomenclature[J]{$\textbf{b}$}{Weight vector for compensator output regression of the AR model, where $\textbf{b} = \mathbb{R}^{N}$}
\nomenclature[J]{$N$}{Number of regressors of the AR model, where $N \in \mathbb{Z}_{>0}$}
\nomenclature[J]{$p_1(t)$}{Corrective ESMU power components from PID$_1$, where $p_1(t) \in \mathbb{R}$}
\nomenclature[J]{$p_2(t)$}{Corrective ESMU power components from PID$_2$, where $p_2(t) \in \mathbb{R}$}
\nomenclature[J]{$SOC_{tol}$}{SOC tolerance, i.e. maximum deviation from the prescheduled SOC profile, where $SOC_{tol} \in [0, 0.5]$}

Inside the PID$_1$ component a SOC error term, $E_\text{SOC}(t)$, is computed.
This term is the difference between the scheduled SOC profile, $SOC(t)$, and the actual (or simulated) SOC values, $SOC^*(t)$.
The following equation captures this error term.

\input{_chapter2/equ/soc-error}

Applying a standard and linearly weighted dynamic gain vector, $\boldsymbol{\alpha}$, to the SOC error allows the calculation of a corrective ESMU power component dynamically.
Here $\boldsymbol{\alpha} = \{\alpha_P, \alpha_I, \alpha_D\}$ and the components are the P, I and D weights, respectively.
How to determine the values of $\boldsymbol{\alpha}$ is explained later in this section.
This corrective power is denoted as $p_1(t+\Delta t)$, and is defined as follows:

\input{_chapter2/equ/corrective-component-soc}

Here the integral component removes steady-state error and the instantaneous error differential prevents overshooting.
All in all, this compensator uses present and past values to issue a corrective future ESMU instruction.
Compensator PID$_2$ on the other hand uses values from the present, past and future in order to minimise the power transient and load peaks.

\input{_chapter2/fig/power-transient-minimisation}

Figure~\ref{ch2:fig:power-transient-minimisation} summarises the time series computations for each power sample at times $t$, $t+\Delta t$, etc.
Ideally, PID$_2$ uses present power readings, $p_\text{net}(t)$, and a power value of the immediate future, i.e. $p_\text{net}(t+\Delta t)$, to compute a power error signal, which is to be reduced to a smallest possible value.
This error signal is defined as:

\input{_chapter2/equ/power-error-signal}

However, since the future network power is unknown an ``estimated next power'', $\hat{p}_\text{net}(t+\Delta t)$, is used instead.
This value is the PID$_2$'s input from the MPC and results in an ``estimated power error signal'':

\input{_chapter2/equ/power-error-estimate}

Similarly to PID$_1$, PID$_2$ produces a corrective ESMU power component, $p_2(t)$, that smoothens the resulting power profile.
This corrective ESMU power is also computed using a standard linear weighted dynamic vector $\boldsymbol{\beta}$, with $\boldsymbol{\beta} = \{\beta_P, \beta_I, \beta_D\}$, being the P, I and D weight, respectively:

\input{_chapter2/equ/corrective-component-power}

Similar to $\boldsymbol{\alpha}$ how to determine the values of $\boldsymbol{\beta}$ is explained later in this section.
Finally, the ``next ESMU power'' can be deduced by adding the two corrective ESMU power components, as shown in the equation below.

\input{_chapter2/equ/next-battery-power}

Both PID compensators do however depend on correctly chosen weights for $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$.
Therefore they need to be tuned prior to executing the dynamic control.
For this work a minimisation problem was formulated that is based on a cost function, $\zeta^*(\boldsymbol{\alpha}, \boldsymbol{\beta})$, to deduce the two weight vectors as follows:

\input{_chapter2/equ/cost-weights}

Here, $\zeta^*(\boldsymbol{\alpha}, \boldsymbol{\beta})$ is defined as:

\input{_chapter2/equ/dynamic-cost}

In Equation~\ref{ch2:equ:cost-weights} and Equation~\ref{ch2:equ:dynamic-cost}, $\zeta^*(\boldsymbol{\alpha}, \boldsymbol{\beta})$ represents the sub-half-hourly peak load during a day when ESMU schedules are adjusted with the corresponding $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$ weights.
Also, the same SOC tolerance that was used to generate the SOC schedule (i.e. $SOC_{tol}$) is included to prevent the solution from deviating off the prescheduled SOC profile.
To generalise this solution for all load cases this minimisation problem was formulated to solve multiple daily load profiles in order to find ideal values for $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$.
This resulting set of $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$ weights therefore guaranteed a convergent and stable solutions for the provided data.
The details concerning these case studies themselves are however outlined in Section~\ref{ch2:sec:case-studies}.

\subsection{Model predictive control}

As explained in the literature review in Chapter~\ref{ch-literature}, Model Predictive Control (MPC) is favoured over Set-Point Control (SPC), since it takes into account time-series to produce a behaviour.
With this knowledge, MPC can be used to not only react to recent changes but also to counteract foreseen trends.
Different approaches exist to obtain these foreseen trends and these approaches highly vary in accuracy, computational burden and robustness.
Equally, the characteristics of underlying data which is used to train these models impacts their performances.
For the presented work in this chapter, an efficient and robust approach is required since potential ESMU deployment with SSEN demands these functional requirements.
Prediction accuracy on the other hand is an optional requirement which becomes important only when the predicting model can issue predictions in real-time and does (for the predicting horizon) remain stationary and bounded.

The simplest form of producing a prediction is to assume that the currently observed trending load will also occur in the future.
This kind of prediction does however not take into account demand dynamics.
%Instead, it uses the mean power which is explained as follows:
%
%\input{_chapter2/equ/simple-prediction}
%
%Here, the estimated next power, $\hat{p}(t+\Delta t)$, is derived as the average past powers, $p(t)$, over an averaging horizon, $N$.
An AR model on the other hand uses a series of past observations and their individual contribution to predict the next power.
But the further into the future these predictions are made the less accurate they become.
This accuracy loss is however circumvented since the hybrid system was designed to only apply corrections based on load predictions of the immediate future (i.e. next sample time at $t+\Delta t$ and not $t+2\Delta t$ or similar).
This simplification also reduces computational burden and guarantees real-time operation especially when choosing the simplest dynamic model (i.e. an Auto-Regressive (AR) model instead of \hlrem{e.g. }deep artificial neural networks).
Since external forces can and often do impact the behaviour of the model, the AR model is treated as an exogenous model with a time-series of input powers, $\textbf{p} = (p(t))$, a time-series of predicted ``next powers'', $\hat{\textbf{p}} = (\hat{p}(t))$, and an internal delay function $t-\Delta t$.

\input{_chapter2/fig/mpc-arx}

Figure~\ref{ch2:fig:mpc-arx} graphically captures the standard AR model's function tree which is equivalently represented mathematically in the following equation:

\input{_chapter2/equ/mpc-arx}

Values of the two weight vectors $\textbf{a}$ and $\textbf{b}$, where $\textbf{a} = (a_i)$ and $\textbf{b} = (b_i)$, are determined during runtime using the standard adaptive least squares algorithm, i.e.:

\input{_chapter2/equ/least-squares}

Therefore, the proposed algorithm adjusts $\textbf{a}$ and $\textbf{b}$ to minimise the prediction error at each time-step.
Beside finding optimised values for $\textbf{a}$ and $\textbf{b}$, the model's number of regressors, $N$, is also expected to impact the model's performance ($N$ is also referred to as the ``model length'').
The example in Figure~\ref{ch2:fig:mpc-arx} represents a symmetric model where $N=3$.
This short length however is most likely insufficient in predicting $p(t+\Delta t)$ which is why several models of increasing lengths are assessed and compared in the results section of this chapter.
From this comparison the impact of $N$ on the models' resulting values of $\hat{p}(t+\Delta t)$ and correspondingly on the performance of the dynamic controller can be determined and discussed.
Details about the cases for different model length are presented in the case studies in Section~\ref{ch2:sec:case-studies}.
